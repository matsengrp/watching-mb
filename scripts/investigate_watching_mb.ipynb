{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import bito\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import os\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'golden.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ly/sv9gn0gj209c7j288m1947lcgv7d5y/T/ipykernel_95468/1611269305.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mpickle_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"golden.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mpp_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredible_set_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mcredible_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredible_set_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m df = mcmc_df_of_topology_sequence(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'golden.pkl'"
     ]
    }
   ],
   "source": [
    "def topology_set_of_path(topologies_path):\n",
    "    with open(topologies_path) as topologies_file:\n",
    "        return {t.strip() for t in topologies_file}\n",
    "\n",
    "\n",
    "def topology_set_to_path(topology_set, topologies_path):\n",
    "    with open(topologies_path, \"w\") as topologies_file:\n",
    "        for topology in topology_set:\n",
    "            topologies_file.write(topology + \"\\n\")\n",
    "\n",
    "\n",
    "def seen_to_file(seen):\n",
    "    topology_set_to_path(\n",
    "        seen, f\"topologies-seen/topologies-seen.{len(seen)}.nwk\")\n",
    "\n",
    "\n",
    "def mcmc_df_of_topology_sequence(topology_sequence_path, pp_dict, credible_set):\n",
    "    pathlib.Path(\"topologies-seen\").mkdir(exist_ok=True)\n",
    "    df = pd.read_csv(\n",
    "        topology_sequence_path, delimiter=\"\\t\", names=[\"dwell_count\", \"topology\"]\n",
    "    )\n",
    "    # The set of topologies seen so far.\n",
    "    seen = set()\n",
    "    # A list that tracks each topology observed in the sequence and marks if it was seen\n",
    "    # for the first time.\n",
    "    first_time = []\n",
    "\n",
    "    for topology in df[\"topology\"]:\n",
    "        if topology in seen:\n",
    "            first_time.append(False)\n",
    "        else:\n",
    "            first_time.append(True)\n",
    "            seen.add(topology)\n",
    "            seen_to_file()\n",
    "    df[\"first_time\"] = first_time\n",
    "    df[\"support_size\"] = df[\"first_time\"].cumsum()\n",
    "    df[\"mcmc_iters\"] = df[\"dwell_count\"].cumsum()\n",
    "    df[\"pp\"] = df[\"topology\"].apply(lambda t: pp_dict.get(t, 0.0))\n",
    "    df[\"total_pp\"] = (df[\"pp\"] * df[\"first_time\"]).cumsum()\n",
    "    df[\"in_credible_set\"] = df[\"topology\"].apply(credible_set.__contains__)\n",
    "    df[\"credible_set_found\"] = (\n",
    "        df[\"in_credible_set\"] & df[\"first_time\"]).cumsum()\n",
    "    df[\"credible_set_frac\"] = df[\"credible_set_found\"] / len(credible_set)\n",
    "    df.set_index(\"mcmc_iters\")\n",
    "    return df\n",
    "\n",
    "\n",
    "pickle_path = \"/golden.pkl\"\n",
    "pp_dict, credible_set_list = pickle.load(open(pickle_path, \"rb\"))\n",
    "credible_set = set(credible_set_list)\n",
    "df = mcmc_df_of_topology_sequence(\n",
    "    \"rerooted-topology-sequence.tab\", pp_dict, credible_set\n",
    ")\n",
    "ax = df[[\"total_pp\", \"credible_set_frac\"]].plot(ylim=[0, 1])\n",
    "ax.figure.savefig(\"accumulation.pdf\")\n",
    "df.to_csv(\"accumulation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_sdag_trees(tmpdir, read_collection_path, write_sdag_trees_path):\n",
    "    fasta_path = \"ds.fasta\"\n",
    "    inst = bito.gp_instance(os.path.join(tmpdir, \"mmap.dat\"))\n",
    "    inst.read_fasta_file(fasta_path)\n",
    "    inst.read_newick_file(read_collection_path)\n",
    "    inst.make_engine()\n",
    "    inst.print_status()\n",
    "    inst.export_all_generated_trees(write_sdag_trees_path)\n",
    "    return inst.dag_summary_statistics()\n",
    "\n",
    "\n",
    "def build_sdag_topologies_set_and_stats(topologies_seen_path):\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        sdag_trees_path = os.path.join(tmpdir, \"generated-trees.nwk\")\n",
    "        sdag_topologies_path = os.path.join(tmpdir, \"sdag-topologies.nwk\")\n",
    "        sdag_summary_stats = build_sdag_trees(\n",
    "            tmpdir, topologies_seen_path, sdag_trees_path\n",
    "        )\n",
    "        # TODO NOTE we have 7 here\n",
    "        subprocess.check_call(\n",
    "            f\"nw_topology {sdag_trees_path} | nw_reroot - 7 | nw_order - \"\n",
    "            f\"> {sdag_topologies_path}\",\n",
    "            shell=True,\n",
    "        )\n",
    "        return topology_set_of_path(sdag_topologies_path), sdag_summary_stats\n",
    "\n",
    "\n",
    "def sdag_results_of_topology_count(topology_count):\n",
    "    topologies_seen_path = f\"topologies-seen/topologies-seen.{topology_count}.nwk\"\n",
    "    sdag_topologies_set, sdag_summary_stats = build_sdag_topologies_set_and_stats(\n",
    "        topologies_seen_path\n",
    "    )\n",
    "    return [\n",
    "        sdag_summary_stats[\"node_count\"],\n",
    "        sdag_summary_stats[\"edge_count\"],\n",
    "        len(credible_set.intersection(sdag_topologies_set)),\n",
    "        len(sdag_topologies_set),\n",
    "        sum(pp_dict.get(t, 0.0) for t in sdag_topologies_set),\n",
    "    ]\n",
    "\n",
    "\n",
    "total_seen_count = (\n",
    "    int(subprocess.check_output(\"ls topologies-seen | wc -l\", shell=True)) + 1\n",
    ")\n",
    "\n",
    "\n",
    "def sdag_results_df_of(max_topology_count):\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        return pd.DataFrame(\n",
    "            pool.map(sdag_results_of_topology_count,\n",
    "                     range(1, max_topology_count + 1)),\n",
    "            columns=[\n",
    "                \"sdag_node_count\",\n",
    "                \"sdag_edge_count\",\n",
    "                \"sdag_topos_in_credible\",\n",
    "                \"sdag_topos_total\",\n",
    "                \"sdag_topos_total_pp\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "\n",
    "sdag_results_df = sdag_results_df_of(10)\n",
    "sdag_results_df.to_csv(\"sdag-results.csv\")\n",
    "\n",
    "\n",
    "sdag_results_df.reset_index(inplace=True)\n",
    "sdag_results_df[\"index\"] += 1\n",
    "sdag_results_df.rename(columns={\"index\": \"support_size\"}, inplace=True)\n",
    "sdag_results_df[\"sdag_credible_set_frac\"] = sdag_results_df[\n",
    "    \"sdag_topos_in_credible\"\n",
    "] / len(credible_set)\n",
    "sdag_results_df.tail()\n",
    "\n",
    "final_df = df.merge(sdag_results_df)\n",
    "final_df.to_csv(\n",
    "    \"final-df.csv\",\n",
    "    columns=[\n",
    "        \"support_size\",\n",
    "        \"mcmc_iters\",\n",
    "        \"total_pp\",\n",
    "        \"in_credible_set\",\n",
    "        \"credible_set_found\",\n",
    "        \"credible_set_frac\",\n",
    "        \"sdag_edge_count\",\n",
    "        \"sdag_node_count\",\n",
    "        \"sdag_topos_in_credible\",\n",
    "        \"sdag_topos_total\",\n",
    "        \"sdag_topos_total_pp\",\n",
    "        \"sdag_credible_set_frac\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "ax = final_df[[\"total_pp\", \"sdag_total_pp\"]].plot(ylim=[0, 1])\n",
    "ax.figure.savefig(\"pp-accumulation.pdf\")\n",
    "\n",
    "ax = final_df[[\"credible_set_frac\", \"sdag_credible_set_frac\"]].plot(ylim=[\n",
    "                                                                    0, 1])\n",
    "ax.figure.savefig(\"credible-accumulation.pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c4e095ca2aafefecbdaff417c80422d897e9585c17b47900f31d33481ded934"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('bito': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
